{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47951dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import os\n",
    "import prody as pro\n",
    "from Bio.SeqUtils import seq1\n",
    "from Bio import pairwise2\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be8fa69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import subplots\n",
    "from itertools import chain, islice\n",
    "from string import ascii_uppercase\n",
    "from numpy.random import choice\n",
    "import matplotlib.pyplot as plt\n",
    "from venn import venn\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "from Bio import pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2d58808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tmtools import tm_align\n",
    "from tmtools.io import get_structure, get_residue_data\n",
    "from tmtools.testing import get_pdb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f9cba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myget_structure(mpath, name):\n",
    "    s2 = get_structure(get_pdb_path(mpath+name))\n",
    "    chain = next(s2.get_chains())\n",
    "    coords2, seq2 = get_residue_data(chain)\n",
    "    return coords2, seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abec1a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance_inverse(str1, str2):\n",
    "    assert len(str1) == len(str2)\n",
    "    return sum(chr1 == chr2 for chr1, chr2 in zip(str1, str2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0635dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_stride_output(af_models_path, stride_out_path):\n",
    "\n",
    "    forstride = os.listdir(af_models_path)\n",
    "    print(forstride)\n",
    "    for f in forstride:\n",
    "        if(f!='.DS_Store'):\n",
    "            filename =  af_models_path+f+'/'+'ranked_0.pdb'\n",
    "            if(os.path.isfile(filename)):\n",
    "                pro.execSTRIDE(filename, outputname=f, outputdir=stride_out_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f11e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stride_to_dict(mpath):\n",
    "\n",
    "    dnumclass = {}\n",
    "    dnumname = {}\n",
    "    with open(mpath+'.stride') as stride:\n",
    "        for line in stride:\n",
    "            if(line.startswith('ASG')):\n",
    "                stridetext = line.split()\n",
    "                resnum = int(stridetext[3])\n",
    "                resname = stridetext[1]\n",
    "                resclass = stridetext[6]\n",
    "                dnumclass[resnum] = resclass\n",
    "                dnumname[resnum] = resname\n",
    "    return dnumclass, dnumname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7344a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1code_seq_from_stride(mfile):\n",
    "\n",
    "    d1_class, d1_name = stride_to_dict(mfile)\n",
    "    s1_3 = ''.join(str(x) for x in d1_name.values())\n",
    "    return seq1(s1_3),d1_class\n",
    "\n",
    "def translate_sse(sse):\n",
    "\n",
    "    sse2 = sse.replace('3','A')\n",
    "    sse3 = sse2.replace('T', 'C')\n",
    "    sse4 = sse3.replace('B', 'C')\n",
    "    return sse4\n",
    "\n",
    "def get_sse_align_seq(aligned_1, d1_class):\n",
    "\n",
    "    arr_sse = []\n",
    "    sse_class = list(d1_class.values())\n",
    "    #print(sse_class)\n",
    "    i = 0\n",
    "    for s in aligned_1:\n",
    "        if (s != '-'):\n",
    "            arr_sse.append(sse_class[i][0])\n",
    "            i += 1\n",
    "        else:\n",
    "            arr_sse.append('-')\n",
    "    sse1 = ''.join(str(x) for x in arr_sse)\n",
    "    #print(sse1)\n",
    "    sse1_trans = translate_sse(sse1)\n",
    "    return sse1_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a21f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_alignments(sse1, sse2, min_align_length):\n",
    "\n",
    "    #print(sse1)\n",
    "    arr_align = []\n",
    "    sse_trans1 = []\n",
    "    sse_trans2 = []\n",
    "    start_origin = 0  # in relation to 1st sequence\n",
    "    start_origin_2 = 0\n",
    "    for i in range(0, len(sse1)):\n",
    "\n",
    "        if ((sse1[i] != '-') and (sse2[i]) != '-'):  # alignment\n",
    "            sse_trans1.append(sse1[i])\n",
    "            sse_trans2.append(sse2[i])\n",
    "        else:\n",
    "            if(len(sse_trans1)>0):\n",
    "                if(len(sse_trans1)>=min_align_length):\n",
    "                    #print('length')\n",
    "                    # print(len(sse_trans1))\n",
    "                    # print(start_origin-len(sse_trans1))\n",
    "                    arr_align.append((start_origin-len(sse_trans1), ''.join(sse_trans1), ''.join(sse_trans2), start_origin_2-len(sse_trans2)))\n",
    "                sse_trans1 = []\n",
    "                sse_trans2 = []\n",
    "        if (sse1[i] != '-'):\n",
    "            start_origin += 1\n",
    "        if (sse2[i] != '-'):\n",
    "            start_origin_2 += 1\n",
    "    # print('arr_align')\n",
    "    # print(arr_align)\n",
    "\n",
    "    return arr_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78104e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_sse(line):\n",
    "\n",
    "    #limited alphabet of sse: ['A','C','T','S']\n",
    "    allsse = ['A', 'C', 'T', 'S']\n",
    "    dict_res = {}\n",
    "    for a in allsse:\n",
    "        rx = r'[^{0}]'.format(a)\n",
    "        arr_sse = (re.split(rx, line))\n",
    "        print(arr_sse)\n",
    "        sub_sse = max(arr_sse, key=len)\n",
    "        dict_res[a] = len(sub_sse)\n",
    "\n",
    "    return dict_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c7ac41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_switch(rr, min_switch_length):\n",
    "\n",
    "    d1 = find_longest_sse(rr[1])\n",
    "    d2 = find_longest_sse(rr[2])\n",
    "    print(d1)\n",
    "    print(d2)\n",
    "    sse1 = (max(d1, key=d1.get))\n",
    "    sse2 = (max(d2, key=d2.get))\n",
    "    print(sse1)\n",
    "    print(sse2)\n",
    "    return (sse1 != sse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53a5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_switch(rr, min_switch_length):\n",
    "    #limited alphabet of sse: ['A','C','S']\n",
    "    lin1 = rr[1]\n",
    "    lin2 = rr[2]\n",
    "    cur_length = 0\n",
    "    max_length = 0\n",
    "    cond_sse = False\n",
    "    cur_pos = 0\n",
    "    max_pos = 0\n",
    "    for i in range(0, len(lin1)):\n",
    "        lin2_sse = lin2[i]\n",
    "        cur_sse = lin1[i]\n",
    "        if cur_sse != lin2_sse:\n",
    "            if(cur_length==0):\n",
    "                cur_pos = i\n",
    "            cur_length += 1\n",
    "            #max_length = max(max_length, cur_length)\n",
    "        else:\n",
    "            if(cur_length>max_length):\n",
    "                max_pos = cur_pos\n",
    "                max_length = cur_length\n",
    "            cur_length = 0\n",
    "    if(max_length>=min_switch_length):\n",
    "        cond_sse =True\n",
    "    return max_length, max_pos, cond_sse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0713ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_switch(rr, min_switch_length):\n",
    "    #limited alphabet of sse: ['A','C','S']\n",
    "    lin1 = rr[1]\n",
    "    lin2 = rr[2]\n",
    "    cur_length = 0\n",
    "    cur_pos = 0\n",
    "    res = []\n",
    "    for i in range(0, len(lin1)):\n",
    "        lin2_sse = lin2[i]\n",
    "        cur_sse = lin1[i]\n",
    "        if cur_sse != lin2_sse:\n",
    "            if(cur_length==0):\n",
    "                cur_pos = i\n",
    "            cur_length += 1\n",
    "        else:\n",
    "            if(cur_length>min_switch_length):\n",
    "                res.append((cur_pos, cur_length,lin1[cur_pos:cur_pos+cur_length],lin2[cur_pos:cur_pos+cur_length]))\n",
    "            cur_length = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250d1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sse_switch(sse1, sse2, min_align_length, min_switch_length, aligned_1, aligned_2):\n",
    "#to allow gaps in alignment change '-' to 'X' \n",
    "    res = []\n",
    "    r = get_array_alignments(sse1, sse2, min_align_length)\n",
    "\n",
    "    #print(r)\n",
    "    for rr in r:\n",
    "        #print(rr)\n",
    "        pos_1 = (rr[0])\n",
    "        pos_2 = (rr[3])\n",
    "\n",
    "        res_cur = get_all_switch(rr, min_switch_length)\n",
    "        #res.append(res_cur)\n",
    "        #print(res_cur)\n",
    "        for k in res_cur:\n",
    "            # print(aligned_1)\n",
    "            # print(aligned_2)\n",
    "            pos1_edit = (k[0])+pos_1\n",
    "            pos2_edit = (k[0]) + pos_2\n",
    "            s1 = aligned_1[pos1_edit:pos1_edit+k[1]]\n",
    "            s2 = aligned_2[pos2_edit:pos2_edit+k[1]]\n",
    "            score_sw = hamming_distance_inverse(s1, s2)/k[1]\n",
    "    \n",
    "            res.append([pos1_edit, pos2_edit, k[1:], score_sw])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fa891a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sse_stride_alignment(m1, m2, mpath):\n",
    "\n",
    "    # m1 = 'ORF_96383_ecoli_2981009-2981191_+'\n",
    "    # m2 = 'ORF_96391_ecoli_2983547-2983744_+'\n",
    "    # mpath = '/Users/hadarovi/addproject/ecoli_newprot/stride/'\n",
    "    \n",
    "    dict_return = {}\n",
    "\n",
    "    s1,d1_class = get_1code_seq_from_stride(mpath+m1)\n",
    "    s2,d2_class = get_1code_seq_from_stride(mpath + m2)\n",
    "\n",
    "    alignments2 = pairwise2.align.localxs(s1, s2, -0.5, -0.0, penalize_extend_when_opening=True)\n",
    "    #print(len(alignments2))\n",
    "    aligned_1 = ((alignments2[0][0]))\n",
    "    aligned_2 = ((alignments2[0][1]))\n",
    "    #print(aligned_1)\n",
    "    #print(aligned_2)\n",
    "    #print('score')\n",
    "    score = (alignments2[0][2])\n",
    "\n",
    "    sse1 = get_sse_align_seq(aligned_1, d1_class)\n",
    "    sse2 = get_sse_align_seq(aligned_2, d2_class)\n",
    "\n",
    "    sse_sim = hamming_distance_inverse(sse1, sse2)\n",
    "\n",
    "    min_align_length = 5\n",
    "    min_switch_length = 5\n",
    "    res = find_sse_switch(sse1, sse2, min_align_length, min_switch_length, s1, s2)\n",
    "    dict_return['align'] = [aligned_1, aligned_2, sse1, sse2]\n",
    "    dict_return['switch'] = res\n",
    "    return dict_return\n",
    "    #return score, sse_sim, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e77db29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bfactor_and_stride(mpath_to_stride,mpath_to_pdb):\n",
    "        d = {}\n",
    "        dn = {}\n",
    "        d1, d2 = stride_to_dict(mpath_to_stride)\n",
    "        s = set()\n",
    "        with open(mpath_to_pdb) as file:\n",
    "            for line in file:\n",
    "                if (line.startswith('ATOM')):\n",
    "\n",
    "                    resname = line[17:20]\n",
    "                    resrel = int(line[22:26])\n",
    "                    resnum = resrel\n",
    "                    bfactor = float(line[60:66].strip())\n",
    "                    dn[resnum] = resname\n",
    "                    sclass = d1[resrel]\n",
    "\n",
    "                    if (resrel not in s):\n",
    "                        if (resnum in d.keys()):\n",
    "                            d[resnum].append((sclass, bfactor))\n",
    "\n",
    "                        else:\n",
    "                            d[resnum] = []\n",
    "                            d[resnum].append((sclass, bfactor))\n",
    "                        s.add(resrel)\n",
    "\n",
    "        return d, dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54724e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strideclass_dict():\n",
    "    aadict = {'A': 1, 'G': 1, 'V': 1, 'M': 2, 'S': 2, 'T': 2, 'Y': 2, 'C': 7, 'D': 6, 'E': 6, 'R': 5, 'K': 5, 'I': 3,\n",
    "              'L': 3, 'F': 3, 'P': 3, 'N': 4, 'Q': 4, 'H': 4, 'W': 4}\n",
    "    amino = sorted(list((aadict.keys())))\n",
    "    thrarr = ['d', 'l', 'm', 'h']\n",
    "    strideclass = sorted(['Coil', 'Turn', 'Strand', 'AlphaHelix', '310Helix', 'Bridge', 'PiHelix'])\n",
    "    keysd = list()\n",
    "    for k in list(amino):\n",
    "        for stride in strideclass:\n",
    "            for thr in thrarr:\n",
    "                keysd.append(str(k) + '-' + str(stride) + '-' + str(thr))\n",
    "\n",
    "    d = dict.fromkeys(keysd, 0)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d6915a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pkl_sse_bfactor(mpath_to_stride,mpath_to_pdb, mpath_to_pkl):\n",
    "\n",
    "    dict_to_save = {}\n",
    "    d, dn = get_bfactor_and_stride(mpath_to_stride, mpath_to_pdb)\n",
    "    dict_to_save['seqlen'] = len(d)\n",
    "    strideclass = sorted(['Coil', 'Turn', 'Strand', 'AlphaHelix', '310Helix', 'Bridge', 'PiHelix'])\n",
    "    for k in strideclass:\n",
    "        dict_to_save[k] = []\n",
    "    #print(d)\n",
    "    for k, v in d.items():\n",
    "        #print(k)\n",
    "        str_class = v[0][0]\n",
    "        #print(v[0][0])\n",
    "        if(str_class in dict_to_save.keys()):\n",
    "            dict_to_save[str_class].append(v[0][1])\n",
    "        else:\n",
    "            print('error')\n",
    "        #print(v[1])\n",
    "    with open(mpath_to_pkl + '_sse_stride_afmodel.pickle', 'wb') as handle:\n",
    "        #print(dict_to_save)\n",
    "        pkl.dump(dict_to_save, handle)\n",
    "    return dict_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68d71a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pkl_sse_bfactor_pipe(mpath,mpath_stride,fprsse):\n",
    "\n",
    "    for s in fprsse:\n",
    "        if(s.startswith('ORF')):\n",
    "            mpath_to_pkl = mpath + s + '/'\n",
    "            filename = mpath + s + '/' + 'ranked_0.pdb'\n",
    "            if (os.path.isfile(filename)):\n",
    "                r = save_to_pkl_sse_bfactor(mpath_stride + s, mpath + s + '/' + 'ranked_0.pdb', mpath_to_pkl)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ef97e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plddt_from_AF(mpath_bio):\n",
    "    \n",
    "    res_plddt2 = {}\n",
    "    atom_len = {}\n",
    "    fprsse = os.listdir(mpath_bio)\n",
    "    fprsse2 = [k for k in fprsse if k.endswith('.pdb')]\n",
    "\n",
    "    for f in fprsse2:\n",
    "        print(f)\n",
    "        test = pro.parsePDB(mpath_bio+f)\n",
    "        b = test.getBetas()\n",
    "        b50 = b[b<50]\n",
    "        atom_len[f] = len(b)\n",
    "        res = len(b50)/len(b)\n",
    "        res_plddt2[f] = (res)\n",
    "    return res_plddt2, atom_len    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89b9a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_structural_info(mpath,mpath_bio,dict_isoforms):\n",
    "    \n",
    "    #mpath = '/Users/hadarovi/addproject/new_transc/clean_data/large_data/'\n",
    "    #mpath_bio = mpath+'all_structures_rank0/'\n",
    "    genes = dict_isoforms.keys()\n",
    "    for g in genes:\n",
    "        #print(g)\n",
    "        pkl_path = mpath+'info/'+g+'/' \n",
    "        d_res = {}\n",
    "        Path(pkl_path).mkdir(parents=True, exist_ok=True)\n",
    "        infog = dict_isoforms[g]  # for each gene g dict contains all isoforms names (AF structure names)\n",
    "\n",
    "        for i in range(0, len(infog)):\n",
    "            mf1 = Path(mpath_bio+infog[i]+'_ranked_0.pdb')\n",
    "            if mf1.is_file():\n",
    "                for j in range(i+1, len(infog)):\n",
    "       \n",
    "                    name1 = infog[i]+'_ranked_0'\n",
    "                    name2 = infog[j]+'_ranked_0'\n",
    "\n",
    "                    mf2 = Path(mpath_bio+infog[j]+'_ranked_0.pdb')\n",
    "                    if mf2.is_file():\n",
    "                        if(name1!=name2):\n",
    "                            coords1, seq1 = myget_structure(mpath_bio, name1)\n",
    "                            coords2, seq2 = myget_structure(mpath_bio, name2)\n",
    "                            res2 = tm_align(coords1, coords2, seq1, seq2)\n",
    "                            res_dict = {}\n",
    "                            res_dict['t'] = res2.t\n",
    "                            res_dict['u'] = res2.u\n",
    "                            res_dict['tm_norm_chain1'] = res2.tm_norm_chain1\n",
    "                            res_dict['tm_norm_chain2'] = res2.tm_norm_chain2\n",
    "                            res_dict['seq1'] = seq1\n",
    "                            res_dict['seq2'] = seq2\n",
    "                            alignments = pairwise2.align.globalxx(seq1, seq2)\n",
    "                            res_dict['nw_1'] = alignments[0].score/(len(seq1))\n",
    "                            res_dict['nw_2'] = alignments[0].score/(len(seq2))\n",
    "                           \n",
    "                            d_res[(name1,name2)]=[(res2.tm_norm_chain1,res2.tm_norm_chain2),(res_dict['nw_1'],res_dict['nw_2'])]\n",
    "                            with open(pkl_path+name1+'#'+name2+'.pickle', 'wb') as handle:\n",
    "                                pkl.dump(res_dict, handle)\n",
    "                               \n",
    "\n",
    "        with open(pkl_path+g+'.pickle', 'wb') as handle2:\n",
    "            pkl.dump(d_res, handle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a013e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_filter_isoforms(mpath_bio):\n",
    "    \n",
    "    res_plddt2, atom_len = get_plddt_from_AF(mpath_bio)\n",
    "    arr_sav = []\n",
    "    max_pldt = []\n",
    "    for g in genes:\n",
    "        #print(g)\n",
    "        pkl_path = mpath+'info/'+g+'/'\n",
    "        mf2 = Path(pkl_path+g+'.pickle')\n",
    "        #print(mf2)\n",
    "        if mf2.is_file():\n",
    "            with open(pkl_path+g+'.pickle', 'rb') as handle:\n",
    "                b = pkl.load(handle)\n",
    "                #print(b)\n",
    "                for k, v in b.items():\n",
    "                    p1 = k[0]+'.pdb'\n",
    "                    #print(p1)\n",
    "                    p2 = k[1]+'.pdb'\n",
    "                    if(p1 in res_plddt2.keys()):\n",
    "                        pl1 = res_plddt2[p1]\n",
    "\n",
    "                    if(p2 in res_plddt2.keys()):\n",
    "                        pl2 = res_plddt2[p2]\n",
    "          \n",
    "                    plddt = max(pl1,pl2)\n",
    "                    if((plddt<=0.4)):\n",
    "                            arr_sav.append((v,g,k,plddt))\n",
    "    return arr_sav                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d5b1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_info_switches(mpath,mpstride,mpath_bio):\n",
    "\n",
    "#     with open(mpath + 'max_v0_l_1.0_max_v1_l_0.1_plddt_lg04_dict_all.pickle', 'rb') as handle:\n",
    "#         b = pkl.load(handle)\n",
    "    b = structure_filter_isoforms(mpath_bio)   \n",
    "    ress = []\n",
    "    dictres = {}\n",
    "    dictresnum = {}\n",
    "    dictres['AC'] = set()\n",
    "    dictres['CS'] = set()\n",
    "    dictres['AS'] = set()\n",
    "    dictresnum['AC'] = 0\n",
    "    dictresnum['CS'] = 0\n",
    "    dictresnum['AS'] = 0\n",
    " \n",
    "    dict_pkl = {}\n",
    "    for k in b:\n",
    "\n",
    "        m1 = k[2][0]+'.pdb'\n",
    "        m2 = k[2][1]+'.pdb'\n",
    "        s = get_sse_stride_alignment(m1, m2, mpstride)\n",
    "        s['scores'] = k\n",
    "        gene = (k[1])\n",
    "\n",
    "        if(len(s['switch'])>0):\n",
    "    \n",
    "            arrs = s['switch']\n",
    "         \n",
    "            for sw in arrs:\n",
    "               \n",
    "                sw1 = sw[2][1]\n",
    "                sw2 = sw[2][2]\n",
    "               \n",
    "                a1 = (collections.Counter(sw1).most_common(1)[0][0])\n",
    "                a2 = (collections.Counter(sw2).most_common(1)[0][0])\n",
    "                code = (sorted(a1+a2))\n",
    "                scode = ''.join(code)\n",
    "                print('code')\n",
    "                print(scode)\n",
    "                dictres[scode].add(gene)\n",
    "                dictresnum[scode]+=1\n",
    "               \n",
    "                lensw = sw[2][0]\n",
    "\n",
    "            ress.append(s)\n",
    "            dict_pkl[k[2]] = s\n",
    "    return ress, dict_pkl\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "845fb4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_SSE():\n",
    "    \n",
    "    mpdb = '/Users/hadarovi/ddcode/prediction/proteomes_calc/human/sse/beta_ex/pdb/'\n",
    "    mstride = '/Users/hadarovi/ddcode/prediction/proteomes_calc/human/sse/beta_ex/stride/'\n",
    "    produce_stride_output(mpdb, mstride)\n",
    "    \n",
    "    save_structural_info(mpath,mpath_bio,dict_isoforms) #dict_isoforms contains names of isoforms for each gene\n",
    "    aggregate_info_switches(mpath, mpstride,mpath_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e999f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
